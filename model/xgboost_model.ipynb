{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "train = pickle.load( open(data_path + 'train_feature_myadding1_reduceDim', 'rb'))\n",
    "print 'loading done'\n",
    "test = pickle.load( open(data_path + 'test_feature_myadding1_reduceDim', 'rb'))\n",
    "print 'loading done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['song_country'] = train['song_country'].astype('category')\n",
    "test['song_country'] = test['song_country'].astype('category')\n",
    "train['artist_name'] = train['artist_name'].astype('category')\n",
    "test['artist_name'] = test['artist_name'].astype('category')\n",
    "train['composer'] = train['composer'].astype('category')\n",
    "test['composer'] = test['composer'].astype('category')\n",
    "train['lyricist'] = train['lyricist'].astype('category')\n",
    "test['lyricist'] = test['lyricist'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "cols = list(train.columns)\n",
    "cols.remove('target')\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype.name == 'category':\n",
    "        train[col] = train[col].cat.codes\n",
    "        test[col] = test[col].cat.codes\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train['genre_ids'].dtype.name == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "X = np.array(train.drop(['target'], axis=1))\n",
    "y = train['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "ids = test['id'].values\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \\\n",
    "#     test_size=0.2, random_state=0)\n",
    "l = int(np.shape(X)[0] * 0.8)\n",
    "X_train, X_valid, y_train, y_valid = X[:l], X[l:], y[:l], y[l:]\n",
    "\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, label=y_valid) \n",
    "d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_valid, y_valid)]\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fold = 5\n",
    "# vals = []\n",
    "# for i in range(fold):\n",
    "#     sample_size = len(X_valSet) * (fold - 1) / fold\n",
    "#     sample_index = np.random.choice(range(len(X_valSet)) ,size = sample_size, replace=False)\n",
    "#     valSet = xgb.DMatrix(X_valid.iloc[sample_index], y_valSet[sample_index])\n",
    "#     real_y = y_valSet[sample_index]\n",
    "#     vals += xgb.DMatrix(X_valSet.iloc[sample_index], y_valSet[sample_index]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'AA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model, evaluate and make predictions\n",
    "def model(eta = 0.7, max_depth = 8):\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eta'] = eta #0.7\n",
    "    params['max_depth'] = max_depth #5\n",
    "    params['silent'] = 1\n",
    "    params['eval_metric'] = 'auc'\n",
    "    params['subsample'] = 1.0 #1.0\n",
    "    params['min_child_weight'] = 5 #5\n",
    "    params['colsample_bytree'] = 0.2 # 0.2\n",
    "    evals_result = {}\n",
    "    \n",
    "    model = xgb.train(params, d_train, 105, watchlist, early_stopping_rounds=100, \\\n",
    "        maximize=True, verbose_eval=200, evals_result = evals_result)\n",
    "\n",
    "    p_test = model.predict(d_test)\n",
    "    print evals_result['train']['auc'][-1], evals_result['valid']['auc'][-1]\n",
    "    return [p_test, [evals_result['train']['auc'][-1], evals_result['valid']['auc'][-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "for max_depth in range(8, 15):\n",
    "    p_test, res = model(max_depth = max_depth)\n",
    "    weights += res,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [x[1] for x in weights]\n",
    "print (weights)\n",
    "#16-20\n",
    "#0.665855, 0.664718, 0.664207, 0.664103, 0.661541\n",
    "##11-15\n",
    "#0.661144, 0.664255, 0.666004, 0.666707, 0.666783\n",
    "#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = np.sum(weights)\n",
    "print (total)\n",
    "result = (np.array(p_tests).T * np.array(weights)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (np.shape(result))\n",
    "mat = np.sum(np.matrix(result), axis = 0)\n",
    "p_test = [x / total for x in (mat.tolist()[0])]\n",
    "print (np.shape(p_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in p_test[:10]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('p_tests.pickle', 'wb') as handle:\n",
    "#     pickle.dump(p_tests, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('weights.pickle', 'wb') as handle:\n",
    "#     pickle.dump(weights, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (np.sum(p_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test\n",
    "print(len(ids), len(p_test))\n",
    "subm.to_csv('../submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
