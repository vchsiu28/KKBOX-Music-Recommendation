{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_cols = ['expiration_date', 'registration_init_time']\n",
    "\n",
    "train_data = pd.read_hdf('../data/train_data.hdf', parse_dates=date_cols)\n",
    "test_data = pd.read_hdf('../data/test_data.hdf', parse_dates=date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 368870, 0, -2556790, 2556790)\n",
      "2556790\n",
      "4820628\n",
      "(-368870, 368870, 1, -2925660, 2556790)\n",
      "2556790\n",
      "4451758\n"
     ]
    }
   ],
   "source": [
    "df_test = test_data\n",
    "df_history_test = train_data\n",
    "\n",
    "df_final_trains = []\n",
    "df_final_history_trains = []\n",
    "\n",
    "n = len(test_data)\n",
    "shift = int(0.05*len(train_data))\n",
    "\n",
    "for i in range(2):\n",
    "    m = -i*shift\n",
    "    print (m, shift, i, -(n + i*shift), n)\n",
    "    if m == 0:\n",
    "        m = None\n",
    "    df_final_trains.append(train_data[-(n + i*shift):m])\n",
    "    df_final_history_trains.append(train_data[:-(n + i*shift)])\n",
    "    print (len(df_final_trains[-1]))\n",
    "    print (len(df_final_history_trains[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_categorical_columns = [\n",
    "    'target', \n",
    "    'song_length', \n",
    "    'registration_init_time', \n",
    "    'expiration_date', \n",
    "    'time', \n",
    "    'bd',\n",
    "]\n",
    "categorical_columns = all_data.columns.difference(not_categorical_columns)\n",
    "\n",
    "orders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    orders[col] = 10 ** (int(np.log(all_data[col].max() + 1) / np.log(10)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_group(df, cols):\n",
    "    \n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n",
    "\n",
    "\n",
    "def mean(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    \n",
    "    mean_map = df_history.groupby(group_history).target.mean()\n",
    "    \n",
    "    return group.map(mean_map).fillna(-1)\n",
    "\n",
    "\n",
    "def count(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_all = get_group(all_data, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "\n",
    "def regression(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    \n",
    "    targets = {}\n",
    "    times = {}\n",
    "    for (y, t), u in zip(df_history[['target', 'time']].values, group_history):\n",
    "        if u not in targets:\n",
    "            targets[u] = [y]\n",
    "            times[u] = [t]\n",
    "        else:\n",
    "            targets[u].append(y)\n",
    "            times[u].append(t)\n",
    "            \n",
    "    linal_user = {}\n",
    "    for u in times:\n",
    "        if len(times[u]) > 1:\n",
    "            A = np.vstack([times[u], np.ones(len(times[u]))]).T\n",
    "            linal_user[u] = np.linalg.inv(A.T.dot(A)).dot(A.T).dot(targets[u])\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for t, u in zip(df['time'], group):\n",
    "        if u not in times:\n",
    "            result.append(0.5)\n",
    "        else:\n",
    "            if len(times[u]) < 2:\n",
    "                result.append(0.5)\n",
    "            else:\n",
    "                result.append(linal_user[u].dot([t, 1]))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def time_from_prev_heard(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "\n",
    "    last_heard = df_history.groupby(group_history).time.last().to_dict()\n",
    "\n",
    "    result = []\n",
    "    for t, g in zip(df.time, group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def time_to_next_heard(df_history, df, cols):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse.time):\n",
    "        if g in next_heard:\n",
    "            result.append(t - next_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_from_future(df_history, df, cols):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_from_past(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def last_time_diff(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "        \n",
    "    last_time = df.groupby(group).time.last()\n",
    "    \n",
    "    return group.map(last_time) - df.time\n",
    "\n",
    "\n",
    "def part_of_unique_song(df):\n",
    "    \n",
    "    group = get_group(all_data, ['msno', 'artist_name'])\n",
    "    group_df = get_group(df, ['msno', 'artist_name'])\n",
    "    \n",
    "    num_song_by_artist = all_data.groupby('artist_name').song_id.nunique()  \n",
    "    num_song_by_user_artist = all_data.groupby(group).song_id.nunique()\n",
    "    \n",
    "    s1 = df.artist_name.map(num_song_by_artist)\n",
    "    s2 = group_df.map(num_song_by_user_artist)\n",
    "    \n",
    "    return s2 / s1\n",
    "\n",
    "\n",
    "def matrix_factorization(df, df_history):\n",
    "    \n",
    "    cols = ['msno', 'source_type']\n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    \n",
    "    df['user_id'] = encoder.transform(group)\n",
    "    df_history['user_id'] = encoder.transform(group_history)\n",
    "\n",
    "    num_users = max(df.user_id.max(), df_history.user_id.max()) + 1\n",
    "    num_items = max(df.song_id.max(), df_history.song_id.max()) + 1\n",
    "    num_msno = max(df.msno.max(), df_history.msno.max()) + 1\n",
    "\n",
    "    M = coo_matrix(\n",
    "        (df_history.target, ( df_history.user_id, df_history.song_id)),\n",
    "        shape=(num_users, num_items)\n",
    "    )\n",
    "\n",
    "    user_features = pd.concat([df, df_history])[['msno', 'user_id']].drop_duplicates()\n",
    "\n",
    "    user_features = coo_matrix(\n",
    "        (np.ones(len(user_features)), (user_features.user_id, user_features.msno)),\n",
    "        shape=(num_users, num_msno)\n",
    "    )\n",
    "\n",
    "    user_features = sp.hstack([sp.eye(num_users), user_features])\n",
    "\n",
    "    model = LightFM(no_components=50, learning_rate=0.1)\n",
    "\n",
    "    model.fit(\n",
    "        M, \n",
    "        epochs=2, \n",
    "        num_threads=50, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    result = model.predict(\n",
    "        df.user_id.values, \n",
    "        df.song_id.values, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col_name(cols, func):\n",
    "    return '_'.join(cols) + '_' + func.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df, df_history):\n",
    "    \n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    for num_col in [1, 2]:\n",
    "        for cols in combinations(categorical_columns, num_col):\n",
    "            for func in [\n",
    "                mean, \n",
    "                count, \n",
    "                time_to_next_heard, \n",
    "                count_from_future,\n",
    "                last_time_diff, \n",
    "                count_from_past\n",
    "            ]:\n",
    "                X[col_name(cols, func)] = func(df_history, df, list(cols))\n",
    "    \n",
    "    for cols in combinations(categorical_columns, 3):\n",
    "        for func in [mean, count]:\n",
    "            X[col_name(cols, func)] = func(df_history, df, list(cols))\n",
    "        if 'msno' in cols:\n",
    "            for func in [time_to_next_heard, last_time_diff, count_from_past]:\n",
    "                X[col_name(cols, func)] = func(df_history, df, list(cols))\n",
    "\n",
    "    for cols in [\n",
    "         ['msno'], \n",
    "         ['msno', 'source_type'], \n",
    "         ['msno', 'genre_ids'], \n",
    "         ['msno', 'artist_name'], \n",
    "         ['msno', 'composer'], \n",
    "         ['msno', 'language'], \n",
    "         ['song_id']\n",
    "     ]:\n",
    "        X[col_name(cols, regression)] = regression(df_history, df, cols)\n",
    "\n",
    "    for cols in [\n",
    "        ['msno'], \n",
    "        ['msno', 'genre_ids'],\n",
    "        ['msno', 'composer'], \n",
    "        ['msno', 'language'], \n",
    "        ['msno','artist_name']\n",
    "    ]:\n",
    "        X[col_name(cols, time_from_prev_heard)] = \\\n",
    "            time_from_prev_heard(df_history, df, cols)\n",
    "\n",
    "    for col in ['song_length', 'bd']:\n",
    "        X[col] = df[col]\n",
    "        \n",
    "    for col in ['expiration_date', 'registration_init_time']:\n",
    "        X[col] = df[col].apply(lambda x: x.toordinal())\n",
    "        \n",
    "    X['part_song_listened'] = df['song_length'] / X['msno_time_to_next_heard'] \n",
    "    X['time_from_test_period'] = np.arange(len(df))\n",
    "    X['part_of_unique_song'] = part_of_unique_song(df)\n",
    "    \n",
    "    X['matrix_factorization'] = matrix_factorization(df, df_history)\n",
    "    \n",
    "    for i in [500000, 2000000]:\n",
    "        for cols in [\n",
    "             ['msno'], \n",
    "             ['msno', 'source_type'], \n",
    "             ['msno', 'genre_ids'], \n",
    "             ['msno', 'artist_name'], \n",
    "             ['msno', 'composer'], \n",
    "             ['msno', 'language'], \n",
    "             ['song_id']\n",
    "        ]:\n",
    "            X[col_name(cols, mean) + str(i)] = mean(df_history[-i:], df, cols)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new features in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xtest = create_features(df_test, df_history_test)\n",
    "Xtrain0 = create_features(df_trains[0], df_history_trains[0])\n",
    "Xtrain1 = create_features(df_trains[1], df_history_trains[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the matrix with new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest.to_hdf('../data/Xtest.hdf', key='abc')\n",
    "Xtrain0.to_hdf('../data/Xtrain0.hdf', key='abc')\n",
    "Xtrain1.to_hdf('../data/Xtrain1.hdf', key='abc')\n",
    "\n",
    "df_trains[0].target.to_hdf('../data/ytrain0.hdf', key='abc')\n",
    "df_trains[1].target.to_hdf('../data/ytrain1.hdf', key='abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
