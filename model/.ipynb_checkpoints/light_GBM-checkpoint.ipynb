{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "train = pickle.load( open(data_path + 'train_feature_myadding1_reduceDim', 'rb'))\n",
    "print 'loading done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "test = pickle.load( open(data_path + 'test_feature_myadding1_reduceDim', 'rb'))\n",
    "print 'loading done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['artist_composer', 'artist_composer_lyricist', 'song_lang_boolean', 'smaller_song', 'count_song_played', \\\n",
    "        'count_artist_played', 'song_country']\n",
    "# 29. artist_composer (0.000000)\n",
    "# 30. artist_composer_lyricist (0.000000)\n",
    "# 31. song_lang_boolean (0.000000)\n",
    "# 32. smaller_song (0.000000)\n",
    "# 33. count_song_played (0.000000)\n",
    "# 34. count_artist_played (0.000000)\n",
    "# 35. song_country (0.000000)\n",
    "#train = train.drop(cols, axis = 1)\n",
    "test = test.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno                  category\n",
      "song_id                  int64\n",
      "source_system_tab     category\n",
      "source_screen_name    category\n",
      "source_type           category\n",
      "target                   uint8\n",
      "song_length             uint32\n",
      "genre_ids             category\n",
      "artist_name           category\n",
      "composer              category\n",
      "lyricist              category\n",
      "language              category\n",
      "city                  category\n",
      "bd                       uint8\n",
      "gender                category\n",
      "registered_via        category\n",
      "expiration_date          int64\n",
      "registration_year        int64\n",
      "registration_month       int64\n",
      "registration_date        int64\n",
      "expiration_year          int64\n",
      "expiration_month         int64\n",
      "membership_days          int64\n",
      "genre_ids_count           int8\n",
      "lyricists_count           int8\n",
      "composer_count            int8\n",
      "is_featured               int8\n",
      "artist_count              int8\n",
      "song_year_y            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(train, open(data_path + 'train_feature_myadding', 'wb'))\n",
    "# pickle.dump(test, open(data_path + 'test_feature_myadding', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test and validation sets\n",
      "Processed data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "\n",
    "X_train = train.drop(['target'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "length = int(len(X_train)*0.8)\n",
    "X_trainSet = X_train[:length]\n",
    "y_trainSet = y_train[:length]\n",
    "X_valSet = X_train[length:]\n",
    "y_valSet =  y_train[length:]\n",
    "# del train, test; gc.collect();\n",
    "\n",
    "# X_trainSet = X_train\n",
    "# y_trainSet = y_train\n",
    "# X_valSet = X_train\n",
    "# y_valSet =  y_train\n",
    "\n",
    "d_train_final = lgb.Dataset(X_trainSet, y_trainSet)\n",
    "watchlist_final = lgb.Dataset(X_valSet, y_valSet)\n",
    "train_final = lgb.Dataset(X_train, y_train)\n",
    "print('Processed data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_model(max_depth = 16, tree = 'gbdt', fold = 5, max_bin = 50, bagging_fraction = 0.95 ):\n",
    "    n_round = 200 + (15 - max_depth) * 25\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': tree,\n",
    "        'learning_rate': 0.6,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': max_bin,\n",
    "        'max_depth': max_depth,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "    frac = 1 - (1.0 / fold)\n",
    "    evals_result = {}\n",
    "    model_f = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=200,\\\n",
    "                              evals_result=evals_result)\n",
    "    print 'done'\n",
    "    p_test = model_f.predict(X_test)\n",
    "    print  'mean=', evals_result['valid_0']['auc'][-1]\n",
    "    return [p_test, evals_result['valid_0']['auc'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_model_final(max_depth = 16, tree = 'gbdt', fold = 5, max_bin = 50, bagging_fraction = 0.95 ):\n",
    "    n_round = 200 + (max_depth - 15) * 5\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': tree,\n",
    "        'learning_rate': 0.6,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': max_bin,\n",
    "        'max_depth': max_depth,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "    evals_result = {}\n",
    "    model_f = lgb.train(params, train_set=train_final,  valid_sets=train_final, verbose_eval=200,\\\n",
    "                              evals_result=evals_result)\n",
    "    print 'done'\n",
    "    p_test = model_f.predict(X_test)\n",
    "    print  'mean=', evals_result['training']['auc'][-1]\n",
    "    return [p_test, evals_result['training']['auc'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dart\n",
      "max_depth... 15\n",
      "[200]\tvalid_0's auc: 0.669546\n",
      "done\n",
      "mean= 0.669546420663\n",
      "max_depth... 16\n",
      "[200]\tvalid_0's auc: 0.668956\n",
      "done\n",
      "mean= 0.668955643671\n",
      "max_depth... 17\n",
      "[200]\tvalid_0's auc: 0.670751\n",
      "done\n",
      "mean= 0.670751241843\n",
      "max_depth... 18\n",
      "[200]\tvalid_0's auc: 0.674192\n",
      "done\n",
      "mean= 0.674192168228\n",
      "max_depth... 19\n",
      "[200]\tvalid_0's auc: 0.672508\n",
      "done\n",
      "mean= 0.672508307597\n",
      "max_depth... 20\n",
      "[200]\tvalid_0's auc: 0.672112\n",
      "done\n",
      "mean= 0.672111574233\n",
      "max_depth... 21\n",
      "[200]\tvalid_0's auc: 0.673609\n",
      "done\n",
      "mean= 0.673608651981\n",
      "max_depth... 22\n",
      "[200]\tvalid_0's auc: 0.674405\n",
      "done\n",
      "mean= 0.674405060155\n",
      "gbdt\n",
      "max_depth... 15\n",
      "[200]\tvalid_0's auc: 0.666838\n",
      "done\n",
      "mean= 0.666837814843\n",
      "max_depth... 16\n",
      "[200]\tvalid_0's auc: 0.666437\n",
      "done\n",
      "mean= 0.666437252796\n",
      "max_depth... 17\n",
      "[200]\tvalid_0's auc: 0.668329\n",
      "done\n",
      "mean= 0.668329181874\n",
      "max_depth... 18\n",
      "[200]\tvalid_0's auc: 0.666712\n",
      "done\n",
      "mean= 0.666711987665\n",
      "max_depth... 19\n",
      "[200]\tvalid_0's auc: 0.667165\n",
      "done\n",
      "mean= 0.667164510717\n",
      "max_depth... 20\n",
      "[200]\tvalid_0's auc: 0.668275\n",
      "done\n",
      "mean= 0.668275194514\n",
      "max_depth... 21\n",
      "[200]\tvalid_0's auc: 0.669572\n",
      "done\n",
      "mean= 0.669572200067\n",
      "max_depth... 22\n",
      "[200]\tvalid_0's auc: 0.6685\n",
      "done\n",
      "mean= 0.668499788444\n"
     ]
    }
   ],
   "source": [
    "weights, p_tests = [], []\n",
    "max_bin = 50\n",
    "for tree in ['dart', 'gbdt']:\n",
    "    print tree\n",
    "    for max_depth in range(15,23,1):\n",
    "        print 'max_depth...', max_depth\n",
    "        p_test, res = lgb_model(tree = tree, max_depth = max_depth)\n",
    "        weights += res,\n",
    "        p_tests += p_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dart\n",
      "max_depth... 28\n",
      "[200]\ttraining's auc: 0.837109\n",
      "done\n",
      "mean= 0.837109407473\n",
      "max_depth... 29\n",
      "[200]\ttraining's auc: 0.837426\n",
      "done\n",
      "mean= 0.837426078896\n",
      "max_depth... 30\n",
      "[200]\ttraining's auc: 0.837214\n",
      "done\n",
      "mean= 0.837213799781\n"
     ]
    }
   ],
   "source": [
    "weights, p_tests = [], []\n",
    "max_bin = 50\n",
    "for tree in ['dart']:\n",
    "    print tree\n",
    "    for max_depth in range(28,31,1):\n",
    "        print 'max_depth...', max_depth\n",
    "        p_test, res= lgb_model_final(tree = tree, max_depth = max_depth)\n",
    "        weights += res,\n",
    "        p_tests += p_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights1 = [(x * 10) ** 2 for x in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print len(weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(p_tests, open(data_path + 'p_tests', 'wb'))\n",
    "# pickle.dump(weights1, open(data_path + 'weights', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done making predictions\n"
     ]
    }
   ],
   "source": [
    "result = (np.array(p_tests).T * np.array(weights)).T\n",
    "print('Done making predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2556790)\n",
      "(2556790,)\n",
      "0.391422638034\n",
      "0.372698401874\n",
      "0.17617924762\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(result))\n",
    "total = np.sum(weights)\n",
    "mat = np.sum(np.matrix(result), axis = 0)\n",
    "p_test = [x / total for x in (mat.tolist()[0])]\n",
    "print (np.shape(p_test))\n",
    "for x in p_test[:3]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions Model model of gbdt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print ('Saving predictions Model model of gbdt')\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test\n",
    "subm.to_csv(data_path + '../submissions/submission_lgbm_27_30.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dart\n",
    "# max_depth... 22\n",
    "# [200]\tvalid_0's auc: 0.683127\n",
    "# done\n",
    "# mean= 0.683126554982\n",
    "# max_depth... 23\n",
    "# [200]\tvalid_0's auc: 0.684025\n",
    "# done\n",
    "# mean= 0.684025200776\n",
    "# max_depth... 24\n",
    "# [200]\tvalid_0's auc: 0.683424\n",
    "# done\n",
    "# mean= 0.683423870829\n",
    "# max_depth... 25\n",
    "# [200]\tvalid_0's auc: 0.683243\n",
    "# done\n",
    "# mean= 0.683242848975\n",
    "# max_depth... 26\n",
    "# [200]\tvalid_0's auc: 0.684003\n",
    "# done\n",
    "# mean= 0.684003282544\n",
    "# max_depth... 27\n",
    "# [200]\tvalid_0's auc: 0.683639\n",
    "# done\n",
    "# mean= 0.683639398343\n",
    "# max_depth... 28\n",
    "# [200]\tvalid_0's auc: 0.683466\n",
    "# done\n",
    "# mean= 0.68346612941\n",
    "# max_depth... 29\n",
    "# [200]\tvalid_0's auc: 0.683804\n",
    "# done\n",
    "# mean= 0.683804281482\n",
    "# max_depth... 30\n",
    "# [200]\tvalid_0's auc: 0.684491\n",
    "# done\n",
    "# mean= 0.684490583375\n",
    "# gbdt\n",
    "# max_depth... 22\n",
    "# [200]\tvalid_0's auc: 0.67788\n",
    "# done\n",
    "# mean= 0.677880199916\n",
    "# max_depth... 23\n",
    "# [200]\tvalid_0's auc: 0.676867\n",
    "# done\n",
    "# mean= 0.676866752141\n",
    "# max_depth... 24\n",
    "# [200]\tvalid_0's auc: 0.677996\n",
    "# done\n",
    "# mean= 0.677996261719\n",
    "# max_depth... 25\n",
    "# [200]\tvalid_0's auc: 0.677539\n",
    "# done\n",
    "# mean= 0.677538786505\n",
    "# max_depth... 26\n",
    "# [200]\tvalid_0's auc: 0.678415\n",
    "# done\n",
    "# mean= 0.678414907137\n",
    "# max_depth... 27\n",
    "# [200]\tvalid_0's auc: 0.678192\n",
    "# done\n",
    "# mean= 0.678191940942\n",
    "# max_depth... 28\n",
    "# [200]\tvalid_0's auc: 0.677959\n",
    "# done\n",
    "# mean= 0.677958934205\n",
    "# max_depth... 29\n",
    "# [200]\tvalid_0's auc: 0.67775\n",
    "# done\n",
    "# mean= 0.677749929258\n",
    "# max_depth... 30\n",
    "# [200]\tvalid_0's auc: 0.678718\n",
    "# done\n",
    "# mean= 0.678718033285"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
